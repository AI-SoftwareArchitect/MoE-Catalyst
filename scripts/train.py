import torch

from config.base_config import device, BrainFormerConfig
from data.loader import load_data, create_batches
from models.brainformer import BrainFormer
from sampling.text_generation import generate_text
from training.train_loop import train_model
from utils.persistence import save_model, load_model

# =============================================================================
# MAIN PROGRAM
# =============================================================================
def main():
    print("ğŸ§  BrainFormer Advanced - Beyin Benzeri Transformer")
    print("=" * 60)
    print(f"Device: {device}")
    if device.type == 'cuda':
        print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    print("=" * 60)

    while True:
        print("\n1 - Train (GeliÅŸmiÅŸ EÄŸitim)")
        print("2 - Run (GeliÅŸmiÅŸ Ã‡alÄ±ÅŸtÄ±rma)")
        print("3 - Exit (Ã‡Ä±kÄ±ÅŸ)")

        choice = input("\nSeÃ§iminiz (1-3): ").strip()

        if choice == "1":
            print("\nğŸ”„ GeliÅŸmiÅŸ eÄŸitim baÅŸlÄ±yor...")

            # Load data
            token_sequences, vocab, word_to_id, id_to_word = load_data()
            print(f"ğŸ“Š Veri yÃ¼klendi - Vocab: {len(vocab)}, Sequences: {len(token_sequences)}")

            # Create config with smaller sequence length
            config = BrainFormerConfig(
                vocab_size=len(vocab),
                max_seq_len=16,
                d_model=128,  # KÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ model boyutu
                num_heads=4,
                num_layers=4,
                ff_hidden_dim=512,  # KÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ FFN
                dropout=0.1
            )

            # Create model
            model = BrainFormer(config).to(device)
            param_count = sum(p.numel() for p in model.parameters())
            print(f"ğŸ—ï¸ Model oluÅŸturuldu - Parametreler: {param_count:,}")

            # Create batches with smaller sequence length
            batches = create_batches(token_sequences, seq_len=16, batch_size=8)
            print(f"ğŸ“¦ Batch'ler hazÄ±rlandÄ±: {len(batches)}")

            if len(batches) == 0:
                print("âŒ Yeterli veri yok!")
                continue

            # Train
            train_model(model, batches, epochs=30, lr=5e-4)  # Reduced epochs

            # Save
            save_model(model, vocab, word_to_id, id_to_word)
            print("âœ… GeliÅŸmiÅŸ eÄŸitim tamamlandÄ±!")

        elif choice == "2":
            print("\nğŸš€ GeliÅŸmiÅŸ model Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")

            # Load model
            model, vocab, word_to_id, id_to_word = load_model()

            if model is None:
                print("âŒ EÄŸitilmiÅŸ model bulunamadÄ±! Ã–nce eÄŸitim yapÄ±n.")
                continue

            print("âœ… GeliÅŸmiÅŸ model yÃ¼klendi!")
            print("ğŸ›ï¸ GeliÅŸmiÅŸ sampling aktif (temperature, top-k, top-p)")

            while True:
                prompt = input("\nPrompt girin (Ã§Ä±kmak iÃ§in 'q'): ")
                if prompt.lower() == 'q':
                    break

                # Generate with different temperatures
                print(f"\nğŸŒ¡ï¸ Temperature KarÅŸÄ±laÅŸtÄ±rmasÄ±:")
                for temp in [0.3, 0.8, 1.2]:
                    generated_text = generate_text(model, vocab, word_to_id, id_to_word, prompt, temperature=temp)
                    print(f"T={temp}: {generated_text}")

        elif choice == "3":
            print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
            break

        else:
            print("âŒ GeÃ§ersiz seÃ§im! LÃ¼tfen 1, 2 veya 3 girin.")
